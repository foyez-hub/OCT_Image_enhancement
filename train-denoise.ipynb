{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport shutil\nfrom PIL import Image\nimport cv2\n\nimport numpy\n\n\ncv2.setUseOptimized(True)\n\n# Parameters initialization\nsigma = 25\nThreshold_Hard3D = 2.7*sigma           # Threshold for Hard Thresholding\nFirst_Match_threshold = 2500             # 用于计算block之间相似度的阈值\nStep1_max_matched_cnt = 16              # 组最大匹配的块数\nStep1_Blk_Size = 8                     # block_Size即块的大小，8*8\nStep1_Blk_Step = 3                      # Rather than sliding by one pixel to every next reference block, use a step of Nstep pixels in both horizontal and vertical directions.\nStep1_Search_Step = 3                   # 块的搜索step\nStep1_Search_Window = 39                # Search for candidate matching blocks in a local neighborhood of restricted size NS*NS centered\n\nSecond_Match_threshold = 400           # 用于计算block之间相似度的阈值\nStep2_max_matched_cnt = 32\nStep2_Blk_Size = 8\nStep2_Blk_Step = 3\nStep2_Search_Step = 3\nStep2_Search_Window = 39\n\nBeta_Kaiser = 2.0\n\n\ndef init(img, _blk_size, _Beta_Kaiser):\n    m_shape = img.shape\n    m_img = numpy.matrix(numpy.zeros(m_shape, dtype=float))\n    m_wight = numpy.matrix(numpy.zeros(m_shape, dtype=float))\n    K = numpy.matrix(numpy.kaiser(_blk_size, _Beta_Kaiser))\n    m_Kaiser = numpy.array(K.T * K)            # 构造一个凯撒窗\n    return m_img, m_wight, m_Kaiser\n\n\ndef Locate_blk(i, j, blk_step, block_Size, width, height):\n    if i*blk_step+block_Size < width:\n        point_x = i*blk_step\n    else:\n        point_x = width - block_Size\n\n    if j*blk_step+block_Size < height:\n        point_y = j*blk_step\n    else:\n        point_y = height - block_Size\n\n    m_blockPoint = numpy.array((point_x, point_y), dtype=int)  # 当前参考图像的顶点\n\n    return m_blockPoint\n\n\ndef Define_SearchWindow(_noisyImg, _BlockPoint, _WindowSize, Blk_Size):\n    point_x = _BlockPoint[0]  # 当前坐标\n    point_y = _BlockPoint[1]  # 当前坐标\n\n    LX = point_x+Blk_Size/2-_WindowSize/2     # 左上x\n    LY = point_y+Blk_Size/2-_WindowSize/2     # 左上y\n    RX = LX+_WindowSize                       # 右下x\n    RY = LY+_WindowSize                       # 右下y\n\n    if LX < 0:   LX = 0\n    elif RX > _noisyImg.shape[0]:   LX = _noisyImg.shape[0]-_WindowSize\n    if LY < 0:   LY = 0\n    elif RY > _noisyImg.shape[0]:   LY = _noisyImg.shape[0]-_WindowSize\n\n    return numpy.array((LX, LY), dtype=int)\n\n\ndef Step1_fast_match(_noisyImg, _BlockPoint):\n    \n    \n    (present_x, present_y) = _BlockPoint  # 当前坐标\n    Blk_Size = Step1_Blk_Size\n    Search_Step = Step1_Search_Step\n    Threshold = First_Match_threshold\n    max_matched = Step1_max_matched_cnt\n    Window_size = Step1_Search_Window\n\n    blk_positions = numpy.zeros((max_matched, 2), dtype=int)  # 用于记录相似blk的位置\n    Final_similar_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float)\n\n    img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n    dct_img = cv2.dct(img.astype(numpy.float64))  # 对目标作block作二维余弦变换\n\n    Final_similar_blocks[0, :, :] = dct_img\n    blk_positions[0, :] = _BlockPoint\n\n    Window_location = Define_SearchWindow(_noisyImg, _BlockPoint, Window_size, Blk_Size)\n    blk_num = (Window_size-Blk_Size)/Search_Step  # 确定最多可以找到多少相似blk\n    blk_num = int(blk_num)\n    (present_x, present_y) = Window_location\n\n    similar_blocks = numpy.zeros((blk_num**2, Blk_Size, Blk_Size), dtype=float)\n    m_Blkpositions = numpy.zeros((blk_num**2, 2), dtype=int)\n    Distances = numpy.zeros(blk_num**2, dtype=float)  # 记录各个blk与它的相似度\n\n    # 开始在_Search_Window中搜索,初始版本先采用遍历搜索策略,这里返回最相似的几块\n    matched_cnt = 0\n    for i in range(blk_num):\n        for j in range(blk_num):\n            tem_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n            dct_Tem_img = cv2.dct(tem_img.astype(numpy.float64))\n            m_Distance = numpy.linalg.norm((dct_img-dct_Tem_img))*2 / (Blk_Size*2)\n\n            # 下面记录数据自动不考虑自身(因为已经记录)\n            if m_Distance < Threshold and m_Distance > 0:  # 说明找到了一块符合要求的\n                similar_blocks[matched_cnt, :, :] = dct_Tem_img\n                m_Blkpositions[matched_cnt, :] = (present_x, present_y)\n                Distances[matched_cnt] = m_Distance\n                matched_cnt += 1\n            present_y += Search_Step\n        present_x += Search_Step\n        present_y = Window_location[1]\n    Distances = Distances[:matched_cnt]\n    Sort = Distances.argsort()\n\n    # 统计一下找到了多少相似的blk\n    if matched_cnt < max_matched:\n        Count = matched_cnt + 1\n    else:\n        Count = max_matched\n\n    if Count > 0:\n        for i in range(1, Count):\n            Final_similar_blocks[i, :, :] = similar_blocks[Sort[i-1], :, :]\n            blk_positions[i, :] = m_Blkpositions[Sort[i-1], :]\n    return Final_similar_blocks, blk_positions, Count\n\n\ndef Step1_3DFiltering(_similar_blocks):\n    '''\n    *3D变换及滤波处理\n    *_similar_blocks:相似的一组block,这里已经是频域的表示\n    *要将_similar_blocks第三维依次取出,然在频域用阈值滤波之后,再作反变换\n    '''\n    statis_nonzero = 0  # 非零元素个数\n    m_Shape = _similar_blocks.shape\n\n    # 下面这一段代码很耗时\n    for i in range(m_Shape[1]):\n        for j in range(m_Shape[2]):\n            tem_Vct_Trans = cv2.dct(_similar_blocks[:, i, j])\n            tem_Vct_Trans[numpy.abs(tem_Vct_Trans[:]) < Threshold_Hard3D] = 0.\n            statis_nonzero += tem_Vct_Trans.nonzero()[0].size\n            _similar_blocks[:, i, j] = cv2.idct(tem_Vct_Trans)[0]\n    return _similar_blocks, statis_nonzero\n\n\ndef Aggregation_hardthreshold(_similar_blocks, blk_positions, m_basic_img, m_wight_img, _nonzero_num, Count, Kaiser):\n    '''\n    *对3D变换及滤波后输出的stack进行加权累加,得到初步滤波的图片\n    *_similar_blocks:相似的一组block,这里是频域的表示\n    *对于最后的数组，乘以凯撒窗之后再输出\n    '''\n    _shape = _similar_blocks.shape\n    if _nonzero_num < 1:\n        _nonzero_num = 1\n    block_wight = (1./_nonzero_num) * Kaiser\n    for i in range(Count):\n        point = blk_positions[i, :]\n        tem_img = (1./_nonzero_num)*cv2.idct(_similar_blocks[i, :, :]) * Kaiser\n        m_basic_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += tem_img\n        m_wight_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += block_wight\n\n\ndef BM3D_1st_step(_noisyImg):\n    \"\"\"第一步,基本去噪\"\"\"\n    # 初始化一些参数：\n    (width, height) = _noisyImg.shape   # 得到图像的长宽\n    block_Size = Step1_Blk_Size         # 块大小\n    blk_step = Step1_Blk_Step           # N块步长滑动\n    Width_num = (width - block_Size)/blk_step\n    Height_num = (height - block_Size)/blk_step\n\n    # 初始化几个数组\n    Basic_img, m_Wight, m_Kaiser = init(_noisyImg, Step1_Blk_Size, Beta_Kaiser)\n\n    # 开始逐block的处理,+2是为了避免边缘上不够\n    for i in range(int(Width_num+2)):\n        for j in range(int(Height_num+2)):\n            # m_blockPoint当前参考图像的顶点\n            m_blockPoint = Locate_blk(i, j, blk_step, block_Size, width, height)       # 该函数用于保证当前的blk不超出图像范围\n            Similar_Blks, Positions, Count = Step1_fast_match(_noisyImg, m_blockPoint)\n            Similar_Blks, statis_nonzero = Step1_3DFiltering(Similar_Blks)\n            Aggregation_hardthreshold(Similar_Blks, Positions, Basic_img, m_Wight, statis_nonzero, Count, m_Kaiser)\n    Basic_img[:, :] /= m_Wight[:, :]\n    basic = numpy.matrix(Basic_img, dtype=int)\n    basic.astype(numpy.uint8)\n\n    return basic\n\n\ndef Step2_fast_match(_Basic_img, _noisyImg, _BlockPoint):\n    '''\n    *快速匹配算法,返回邻域内寻找和当前_block相似度最高的几个block,要同时返回basicImg和IMG\n    *_Basic_img: 基础去噪之后的图像\n    *_noisyImg:噪声图像\n    *_BlockPoint:当前block的坐标及大小\n    '''\n    (present_x, present_y) = _BlockPoint  # 当前坐标\n    Blk_Size = Step2_Blk_Size\n    Threshold = Second_Match_threshold\n    Search_Step = Step2_Search_Step\n    max_matched = Step2_max_matched_cnt\n    Window_size = Step2_Search_Window\n\n    blk_positions = numpy.zeros((max_matched, 2), dtype=int)  # 用于记录相似blk的位置\n    Final_similar_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float)\n    Final_noisy_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float)\n\n    img = _Basic_img[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n    dct_img = cv2.dct(img.astype(numpy.float32))  # 对目标作block作二维余弦变换\n    Final_similar_blocks[0, :, :] = dct_img\n\n    n_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n    dct_n_img = cv2.dct(n_img.astype(numpy.float32))  # 对目标作block作二维余弦变换\n    Final_noisy_blocks[0, :, :] = dct_n_img\n\n    blk_positions[0, :] = _BlockPoint\n\n    Window_location = Define_SearchWindow(_noisyImg, _BlockPoint, Window_size, Blk_Size)\n    blk_num = (Window_size-Blk_Size)/Search_Step  # 确定最多可以找到多少相似blk\n    blk_num = int(blk_num)\n    (present_x, present_y) = Window_location\n\n    similar_blocks = numpy.zeros((blk_num**2, Blk_Size, Blk_Size), dtype=float)\n    m_Blkpositions = numpy.zeros((blk_num**2, 2), dtype=int)\n    Distances = numpy.zeros(blk_num**2, dtype=float)  # 记录各个blk与它的相似度\n\n    # 开始在_Search_Window中搜索,初始版本先采用遍历搜索策略,这里返回最相似的几块\n    matched_cnt = 0\n    for i in range(blk_num):\n        for j in range(blk_num):\n            tem_img = _Basic_img[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n            dct_Tem_img = cv2.dct(tem_img.astype(numpy.float32))\n            m_Distance = numpy.linalg.norm((dct_img-dct_Tem_img))*2 / (Blk_Size*2)\n\n            # 下面记录数据自动不考虑自身(因为已经记录)\n            if m_Distance < Threshold and m_Distance > 0:\n                similar_blocks[matched_cnt, :, :] = dct_Tem_img\n                m_Blkpositions[matched_cnt, :] = (present_x, present_y)\n                Distances[matched_cnt] = m_Distance\n                matched_cnt += 1\n            present_y += Search_Step\n        present_x += Search_Step\n        present_y = Window_location[1]\n    Distances = Distances[:matched_cnt]\n    Sort = Distances.argsort()\n\n    # 统计一下找到了多少相似的blk\n    if matched_cnt < max_matched:\n        Count = matched_cnt + 1\n    else:\n        Count = max_matched\n\n    if Count > 0:\n        for i in range(1, Count):\n            Final_similar_blocks[i, :, :] = similar_blocks[Sort[i-1], :, :]\n            blk_positions[i, :] = m_Blkpositions[Sort[i-1], :]\n\n            (present_x, present_y) = m_Blkpositions[Sort[i-1], :]\n            n_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size]\n            Final_noisy_blocks[i, :, :] = cv2.dct(n_img.astype(numpy.float64))\n\n    return Final_similar_blocks, Final_noisy_blocks, blk_positions, Count\n\n\ndef Step2_3DFiltering(_Similar_Bscs, _Similar_Imgs):\n    '''\n    *3D维纳变换的协同滤波\n    *_similar_blocks:相似的一组block,这里是频域的表示\n    *要将_similar_blocks第三维依次取出,然后作dct,在频域进行维纳滤波之后,再作反变换\n    *返回的Wiener_wight用于后面Aggregation\n    '''\n    m_Shape = _Similar_Bscs.shape\n    Wiener_wight = numpy.zeros((m_Shape[1], m_Shape[2]), dtype=float)\n\n    for i in range(m_Shape[1]):\n        for j in range(m_Shape[2]):\n            tem_vector = _Similar_Bscs[:, i, j]\n            tem_Vct_Trans = numpy.matrix(cv2.dct(tem_vector))\n            Norm_2 = numpy.float64(tem_Vct_Trans.T * tem_Vct_Trans)\n            m_weight = Norm_2/(Norm_2 + sigma**2)\n            if m_weight != 0:\n                Wiener_wight[i, j] = 1./(m_weight*2 * sigma*2)\n            # else:\n            #     Wiener_wight[i, j] = 10000\n            tem_vector = _Similar_Imgs[:, i, j]\n            tem_Vct_Trans = m_weight * cv2.dct(tem_vector)\n            _Similar_Bscs[:, i, j] = cv2.idct(tem_Vct_Trans)[0]\n\n    return _Similar_Bscs, Wiener_wight\n\n\ndef Aggregation_Wiener(_Similar_Blks, _Wiener_wight, blk_positions, m_basic_img, m_wight_img, Count, Kaiser):\n    '''\n    *对3D变换及滤波后输出的stack进行加权累加,得到初步滤波的图片\n    *_similar_blocks:相似的一组block,这里是频域的表示\n    *对于最后的数组，乘以凯撒窗之后再输出\n    '''\n    _shape = _Similar_Blks.shape\n    block_wight = _Wiener_wight # * Kaiser\n\n    for i in range(Count):\n        point = blk_positions[i, :]\n        tem_img = _Wiener_wight * cv2.idct(_Similar_Blks[i, :, :]) # * Kaiser\n        m_basic_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += tem_img\n        m_wight_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += block_wight\n\n\ndef BM3D_2nd_step(_basicImg, _noisyImg):\n    '''Step 2. 最终的估计: 利用基本的估计，进行改进了的分组以及协同维纳滤波'''\n    # 初始化一些参数：\n    (width, height) = _noisyImg.shape\n    block_Size = Step2_Blk_Size\n    blk_step = Step2_Blk_Step\n    Width_num = (width - block_Size)/blk_step\n    Height_num = (height - block_Size)/blk_step\n\n    # 初始化几个数组\n    m_img, m_Wight, m_Kaiser = init(_noisyImg, block_Size, Beta_Kaiser)\n\n    for i in range(int(Width_num+2)):\n        for j in range(int(Height_num+2)):\n            m_blockPoint = Locate_blk(i, j, blk_step, block_Size, width, height)\n            Similar_Blks, Similar_Imgs, Positions, Count = Step2_fast_match(_basicImg, _noisyImg, m_blockPoint)\n            Similar_Blks, Wiener_wight = Step2_3DFiltering(Similar_Blks, Similar_Imgs)\n            Aggregation_Wiener(Similar_Blks, Wiener_wight, Positions, m_img, m_Wight, Count, m_Kaiser)\n    m_img[:, :] /= m_Wight[:, :]\n    Final = numpy.matrix(m_img, dtype=int)\n    Final.astype(numpy.uint8)\n\n    return Final\n\ninput_directory = '2'  # Replace with your input directory path\noutput_directory = 'output2'\n\nif  __name__ == '__main__':\n\n    cv2.setUseOptimized(True)\n\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n\n    # Iterate through each folder in the input directory\n    for folder_name in os.listdir(input_directory):\n        folder_path = os.path.join(input_directory, folder_name)\n\n        if os.path.isdir(folder_path):\n            # Create corresponding output folder\n            output_folder_path = os.path.join(output_directory, folder_name)\n            if not os.path.exists(output_folder_path):\n                os.makedirs(output_folder_path)\n\n            # Iterate through each image in the folder\n            for file_name in os.listdir(folder_path):\n                file_path = os.path.join(folder_path, file_name)\n\n                if os.path.isfile(file_path) and file_name.lower().endswith(('tiff', 'jpg', 'jpeg', 'bmp', 'gif', 'png')):\n                    # Read the image\n                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n\n                    if img is not None:\n                        # Record the start time\n                        e1 = cv2.getTickCount()\n\n                        # Process the image with the first step of BM3D\n                        Basic_img = BM3D_1st_step(img)\n                        e2 = cv2.getTickCount()\n                        time = (e2 - e1) / cv2.getTickFrequency()\n                        print(f\"The Processing time of the First step is {time} s for {file_name}\")\n\n                        # Save the Basic image as a .jpg file\n                        basic_img_name = os.path.splitext(file_name)[0] + \".jpg\"\n                        basic_img_path = os.path.join(output_folder_path, basic_img_name)\n                        cv2.imwrite(basic_img_path, Basic_img)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}